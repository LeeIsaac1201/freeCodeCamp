try:
  # This command only in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import numpy as np
import matplotlib.pyplot as plt

# Get project files
!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip

!unzip cats_and_dogs.zip

PATH = 'cats_and_dogs'

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')
test_dir = os.path.join(PATH, 'test')

# Get number of files in each directory. The train and validation directories.
# Each has the subdirectories "dogs" and "cats."
total_train = sum([len(files) for r, d, files in os.walk(train_dir)])
total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])
total_test = len(os.listdir(test_dir))

# Variables for pre-processing and training.
batch_size = 128
epochs = 15
IMG_HEIGHT = 150
IMG_WIDTH = 150

# 3
# These create image data generators for training, validation, and testing datasets.
# The rescale=1/255 normalises pixel values from [0,255] to [0,1], which helps the model train more effectively.
train_image_generator = ImageDataGenerator(rescale=1/255)
validation_image_generator = ImageDataGenerator(rescale=1/255)
test_image_generator = ImageDataGenerator(rescale=1/255)

# Load training images from the 'train' directory.
# batch_size: The number of images processed at once during training.
# target_size: Resize all images to (IMG_HEIGHT, IMG_WIDTH).
# class_mode='binary': Labels are either 0 (cat) or 1 (dog).
train_data_gen = train_image_generator.flow_from_directory(
    batch_size=batch_size,
    directory=train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary'
)

validation_data_gen = validation_image_generator.flow_from_directory(
    batch_size=batch_size,
    directory=validation_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary'
)

test_data_gen = test_image_generator.flow_from_directory(
    batch_size=batch_size,
    directory=test_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode=None,
    shuffle=False
)

# 4
def plotImages(images_arr, probabilities = False):
    # Create a figure with subplots, one for each image in images_arr.
    # figsize is set so each image has enough vertical space.
    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))
    # Case 1: No probabilities provided (just show images).
    if probabilities is False:
      for img, ax in zip( images_arr, axes):
          ax.imshow(img)
          ax.axis('off')
    # Case 2: Probabilities provided (show images with predicted labels).
    else:
      for img, probability, ax in zip( images_arr, probabilities, axes):
          ax.imshow(img)
          ax.axis('off')
          if probability > 0.5:
              # If probability > 0.5, model predicts "dog."
              ax.set_title("%.2f" % (probability*100) + "% dog")
          else:
              # Otherwise, model predicts "cat."
              ax.set_title("%.2f" % ((1-probability)*100) + "% cat")
    # Show the final plot with all images.
    plt.show()
# Get a batch of training images from the generator, and train_data_gen yields batches of (images, labels).
sample_training_images, _ = next(train_data_gen)
# Plot the first five images from the batch.
plotImages(sample_training_images[:5])

# 5
# Create an ImageDataGenerator for training images with data augmentation. This helps prevent overfitting by generating new variations of existing images.
train_image_generator = ImageDataGenerator(
    rescale=1/255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# 6
# Create a training data generator with augmented images from the train directory.
train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                     directory=train_dir,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     class_mode='binary')

# Generate five augmented versions of the first training image.
augmented_images = [train_data_gen[0][0][0] for i in range(5)]

# Display the augmented images to visualise transformations.
plotImages(augmented_images)

# 7
# Build a Sequential Convolutional Neural Network (CNN) model for binary classification (cats versus dogs)
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model with Adam optimiser, binary crossentropy loss, and accuracy metric.
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 8
# Train the model using the training data generator.
history = model.fit(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / batch_size)),
    epochs=epochs,
    validation_data=validation_data_gen,
    validation_steps=int(np.ceil(total_val / batch_size))
)

# 9
acc = history.history['accuracy'] # Extract training accuracy values from history.
val_acc = history.history['val_accuracy'] # Extract validation accuracy values from history.

loss = history.history['loss'] # Extract training loss values from history.
val_loss = history.history['val_loss'] # Extract validation loss values from history.

epochs_range = range(epochs) # Create a range object for the number of epochs.

plt.figure(figsize=(8, 8)) # Set up the figure size for the plots.
# Plot training versus validation accuracy.
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Plot training versus validation loss.
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show() # Display the plots.

# 10
# Initialise empty lists to store test images and their predicted probabilities.
test_images = []
probabilities = []

# Get sorted list of all image files in the test directory.
test_image_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

# Loop through each test image file.
for img_name in test_image_files:
    img_path = os.path.join(test_dir, img_name)
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = img_array / 255.0
    test_images.append(img_array)

    img_batch = tf.expand_dims(img_array, 0)
    prob = model.predict(img_batch, verbose=0)
    probabilities.append(prob[0][0])

# Convert lists to numpy arrays for easier handling.
test_images = np.array(test_images)
probabilities = np.array(probabilities)

# Plot test images with predicted probabilities (dog versus cat labels).
plotImages(test_images, probabilities)

# 11
answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,
            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,
            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,
            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,
            0, 0, 0, 0, 0, 0]

correct = 0

for probability, answer in zip(probabilities, answers):
  if round(probability) == answer:
    correct +=1

percentage_identified = (correct / len(answers)) * 100

passed_challenge = percentage_identified >= 63

print(f"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.")

if passed_challenge:
  print("You passed the challenge!")
else:
  print("You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!")
